{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c7ed094-2596-4ad6-8a5b-2ffd59fea568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77499f-7f18-4a2c-a337-a938134a3641",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "Imported required libraries for model evaluation:\n",
    "- `joblib` to load saved model  \n",
    "- `sklearn.metrics` for classification metrics  \n",
    "- `matplotlib` and `seaborn` for visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3785a47-86cf-4e8f-9ca4-fe46bc5a9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed_data.csv\")\n",
    "\n",
    "if \"customerID\" in df.columns:\n",
    "     df.drop(\"customerID\", axis=1, inplace=True)\n",
    "\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3139a-cd1f-4344-909f-660d650faa0c",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "Loaded the processed dataset and separated:\n",
    "- **X** → feature matrix  \n",
    "- **y** → target variable (Churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2df02352-f15e-42ef-b020-ea583596f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123dfe8f-f8a5-464c-9d5a-614599ffc711",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "Performed the same train-test split used during model training to ensure consistency in evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c608862f-5821-435b-b748-5d62c333c1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "model = joblib.load(\"../data/customer_churn_model_tuned.pkl\")\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f084c5-4587-4cb1-8175-bc621e8ccffc",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "Loaded the previously saved **Random Forest model** for evaluation on unseen test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5377287-a676-4079-8730-f725ce5472c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b196b-e45f-4790-9376-7626e3fb6d74",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- `y_pred` → predicted class labels (0/1)  \n",
    "- `y_prob` → predicted probabilities for ROC-AUC calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26ac84f7-f428-47d6-b5da-b493740cb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7789623312011372\n",
      "Precision: 0.5683297180043384\n",
      "Recall: 0.7005347593582888\n",
      "F1 Score: 0.6275449101796408\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1033\n",
      "           1       0.57      0.70      0.63       374\n",
      "\n",
      "    accuracy                           0.78      1407\n",
      "   macro avg       0.72      0.75      0.74      1407\n",
      "weighted avg       0.80      0.78      0.79      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109b833-ca21-41b1-a414-24c7d9cb1fc1",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "Evaluated model performance using:\n",
    "- **Accuracy** → overall correctness  \n",
    "- **Precision** → correctness of churn predictions  \n",
    "- **Recall** → ability to detect actual churners (very important)  \n",
    "- **F1-score** → balance between precision and recall\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
